{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYfsxNexaoxW","executionInfo":{"status":"ok","timestamp":1700046623232,"user_tz":-60,"elapsed":34068,"user":{"displayName":"Mirja Vink","userId":"07622607045396072683"}},"outputId":"9f34b3ec-083f-4539-a73e-f55c5a424757"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"vsu7uDRVZXBs"},"source":["This code was used to get the correct sets for train, validation and test based on the amount of frames to be used. This code was run four times, for 16 frames, 32 frames, 48 frames and for the full video length. The code reduces the frames by skipping every 2 or 3 frames to reduce the length to 16 frames while keeping the temporal aspect of 32, 48 or full video.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hnRmr1jVZQoT"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import concurrent.futures\n","\n","folder_path = 'drive/MyDrive/Colab Notebooks/Approach_100'\n","training_path = 'drive/MyDrive/Colab Notebooks/frames/train56'\n","validation_path = 'drive/MyDrive/Colab Notebooks/frames/validation56'\n","test_path = 'drive/MyDriveframes/Colab Notebooks/test56'\n","\n","get_percentage = False\n","frame_num = 56 #change to desired number of frames\n","\n","\n","def get_all_mp4_files(folder):\n","    # Get a list of all files in the directory\n","    file_list = os.listdir(folder)\n","\n","    # Filter the list to include only .mp4 files\n","    mp4_files = [f for f in file_list if f.endswith('.mp4')]\n","\n","    return mp4_files\n","\n","\n","def split_videos_in_sets(mp4_files):\n","    train_set = []\n","    val_set = []\n","    test_set = []\n","\n","    for file in mp4_files:\n","        # Extract the substring from the file name\n","        first_number = int(file.split('-')[0].replace('d', ''))\n","\n","        if first_number >= 20:\n","            test_set.append(file)\n","        elif first_number >= 18:\n","            val_set.append(file)\n","        else:\n","            train_set.append(file)\n","\n","    return train_set, val_set, test_set\n","\n","\n","def get_frames_to_extract(frame_count, num_frames):\n","    if frame_count < 16:\n","        print(f\"Error too little frames! It will duplicate some frames to reach 16 frames.\")\n","\n","    values = np.linspace(0, (frame_count - 1), num_frames)\n","    return np.array([round(i) for i in values])\n","\n","\n","def preprocess_video_steps(video_path, output_path, num_frames, get_percentage, frame_count):\n","    # Initialize an empty list to store frames\n","    frames = []\n","\n","    # Open the video file using OpenCV\n","    video = cv2.VideoCapture(video_path)\n","\n","    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","    if get_percentage:\n","        frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n","    elif int(video.get(cv2.CAP_PROP_FRAME_COUNT)) < frame_count:\n","        frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    frames_to_extract = get_frames_to_extract(frame_count, num_frames)\n","\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    out = cv2.VideoWriter(output_path, fourcc, video.get(cv2.CAP_PROP_FPS), (frame_width, frame_height))\n","\n","    # Initialize the frame index\n","    frame_index = 0\n","    frame_extracted = 0\n","\n","    while True:\n","        # Read the next frame from the video\n","        ret, frame = video.read()\n","\n","        # Check if there are no more frames to read\n","        if not ret:\n","            break\n","\n","        # Check if we have processed the desired number of frames\n","        if frame_extracted == num_frames:\n","            break\n","\n","        if frame_index in frames_to_extract:\n","            out.write(frame)\n","            frame_extracted += 1\n","\n","        # Increment the frame index\n","        frame_index += 1\n","\n","    video.release()\n","\n","    zero_padded = 0\n","    # Zero pad frames to num_frames if necessary\n","    while frame_extracted < num_frames:\n","        # Create a black frame\n","        black_frame = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n","        out.write(black_frame)\n","        frame_extracted += 1\n","        zero_padded += 1\n","\n","    out.release()\n","    print(f\"Looped over {frame_index} frames for {video_path} with {zero_padded} zeropad\")\n","    return frames\n","\n","\n","def get_frame_count(file):\n","    cap = cv2.VideoCapture(file)\n","    return int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","\n","def process_file(file, input_dir, output_dir, num_frames, get_percentage, frame_count):\n","    vid_path = os.path.join(input_dir, file)\n","    out_path = os.path.join(output_dir, file)\n","    preprocess_video_steps(vid_path, out_path, num_frames, get_percentage, frame_count)\n","    if get_frame_count(out_path) != num_frames:\n","        print(f\"Incorrect frame count for: {out_path}\")\n","\n","\n","def get_frames_for_files(files, input_dir, output_dir, get_percentage=True, frame_count=48, num_frames=16):\n","    with concurrent.futures.ThreadPoolExecutor() as executor:\n","        executor.map(lambda file: process_file(file, input_dir, output_dir, num_frames, get_percentage, frame_count),\n","                     files)\n","\n","\n","files = get_all_mp4_files(folder_path)\n","train_set, val_set, test_set = split_videos_in_sets(files)\n","\n","get_frames_for_files(train_set, folder_path, training_path, get_percentage, frame_num)\n","get_frames_for_files(val_set, folder_path, validation_path, get_percentage, frame_num)\n","get_frames_for_files(test_set, folder_path, test_path, get_percentage, frame_num)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17043,"status":"ok","timestamp":1700046788404,"user":{"displayName":"Mirja Vink","userId":"07622607045396072683"},"user_tz":-60},"id":"QHe_SYMzhzRk","outputId":"43f66680-f5d9-4182-e54e-84af49d67d6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total frames in '/content/drive/MyDrive/Colab Notebooks /Approach_100/d7-rB-s4-a7_100.mp4': 263\n","Total frames in '/content/drive/MyDrive/Colab Notebooks /frames/train16/d7-rB-s4-a7_100.mp4': 16\n","Total frames in '/content/drive/MyDrive/Colab Notebooks /frames/train32/d7-rB-s4-a7_100.mp4': 16\n","Total frames in '/content/drive/MyDrive/Colab Notebooks /frames/train48/d1-rB-s4-a8_100.mp4': 16\n","Total frames in '/content/drive/MyDrive/Colab Notebooks /frames/train64/d1-rB-s4-a8_100.mp4': 16\n","Total frames in '/content/drive/MyDrive/Colab Notebooks /frames/train_full/d1-rB-s4-a8_100.mp4': 16\n"]}],"source":["#check framelength for an orginally 8-second video\n","\n","#file d7-rB-s4-a7_100.mp4 is orginally 8.78 seconds\n","\n","import cv2\n","\n","def count_frames(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","\n","    if not cap.isOpened():\n","        print(\"Error: Couldn't open the video file.\")\n","        return -1\n","\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    return total_frames\n","\n","# Example usage:\n","video_file_path = '/content/drive/MyDrive/Colab Notebooks /Approach_100/d7-rB-s4-a7_100.mp4'  # Replace with your video file path\n","frame_count = count_frames(video_file_path)\n","\n","if frame_count != -1:\n","    print(f\"Total frames in '{video_file_path}': {frame_count}\")\n","\n","#16frames\n","video_file_path = '/content/drive/MyDrive/Colab Notebooks /frames/train16/d7-rB-s4-a7_100.mp4'  # Replace with your video file path\n","frame_count = count_frames(video_file_path)\n","\n","if frame_count != -1:\n","    print(f\"Total frames in '{video_file_path}': {frame_count}\")\n","\n","#32frames\n","video_file_path = '/content/drive/MyDrive/Colab Notebooks /frames/train32/d7-rB-s4-a7_100.mp4'  # Replace with your video file path\n","frame_count = count_frames(video_file_path)\n","\n","if frame_count != -1:\n","    print(f\"Total frames in '{video_file_path}': {frame_count}\")\n","#48frames\n","\n","video_file_path = '/content/drive/MyDrive/Colab Notebooks /frames/train48/d1-rB-s4-a8_100.mp4'  # Replace with your video file path\n","frame_count = count_frames(video_file_path)\n","\n","if frame_count != -1:\n","  print(f\"Total frames in '{video_file_path}': {frame_count}\")\n","\n","#56frames\n","\n","video_file_path = '/content/drive/MyDrive/Colab Notebooks /frames/train64/d1-rB-s4-a8_100.mp4'  # Replace with your video file path\n","frame_count = count_frames(video_file_path)\n","\n","if frame_count != -1:\n","  print(f\"Total frames in '{video_file_path}': {frame_count}\")\n","\n","#full_set\n","\n","video_file_path = '/content/drive/MyDrive/Colab Notebooks /frames/train_full/d1-rB-s4-a8_100.mp4'  # Replace with your video file path\n","frame_count = count_frames(video_file_path)\n","\n","if frame_count != -1:\n","  print(f\"Total frames in '{video_file_path}': {frame_count}\")\n","\n","\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCjYNX/v59yoJ7OYGeV3RZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}